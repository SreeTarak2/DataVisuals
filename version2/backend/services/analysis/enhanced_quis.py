# backend/services/analysis/enhanced_quis.py

"""
Enhanced QUIS: Question-guided Unified Insight Search
======================================================

Research-backed implementation based on EMNLP 2024 paper:
"QUIS: Question-guided Insights Generation for Automated Exploratory Data Analysis"

Key Features:
1. LLM-driven question generation (QUGEN) - Proposes hypotheses based on dataset
2. Beam search subspace exploration - Intelligent pruning instead of exhaustive search
3. Statistical significance testing - Fisher's z-test for correlation comparisons
4. FDR correction - Benjamini-Hochberg procedure for multiple testing
5. Simpson's Paradox detection - Catches dangerous trend reversals
6. Insight ranking - Score by significance × effect size × novelty

Author: DataSage AI
"""

import logging
import numpy as np
import polars as pl
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict, field
from heapq import heappush, heappop, nlargest
from itertools import combinations
from scipy import stats
import json

from services.analysis.advanced_stats import (
    hypothesis_tester,
    correlation_analyzer,
    EffectSizeCalculator,
    ConfidenceIntervalCalculator
)

logger = logging.getLogger(__name__)


# ============================================================
# DATA STRUCTURES
# ============================================================

@dataclass
class AnalyticalQuestion:
    """A hypothesis generated by QUGEN."""
    question: str
    question_type: str  # "correlation", "comparison", "trend", "distribution", "anomaly"
    target_columns: List[str]
    filter_column: Optional[str] = None
    priority: float = 1.0
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class QUISInsight:
    """A statistically validated insight from ISGEN."""
    insight_type: str
    description: str
    columns: List[str]
    subspace: Optional[Dict[str, Any]] = None
    statistic: float = 0.0
    p_value: float = 1.0
    effect_size: float = 0.0
    effect_interpretation: str = ""
    confidence_interval: Optional[Tuple[float, float]] = None
    sample_size: int = 0
    is_simpson_paradox: bool = False
    novelty_score: float = 0.0
    overall_score: float = 0.0  # Combined ranking score
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        if result['confidence_interval']:
            result['confidence_interval'] = list(result['confidence_interval'])
        return result


@dataclass 
class SubspaceCandidate:
    """A candidate subspace in beam search."""
    filters: Dict[str, Any]  # e.g., {"region": "North", "category": "Electronics"}
    score: float = 0.0
    n_samples: int = 0
    depth: int = 0
    
    def __lt__(self, other):
        # For min-heap (we want max scores, so invert)
        return self.score > other.score


# ============================================================
# QUGEN: LLM-DRIVEN QUESTION GENERATION
# ============================================================

class QuestionGenerator:
    """
    QUGEN: Generates analytical questions using LLM based on dataset semantics.
    Questions guide the insight search process.
    """
    
    def __init__(self):
        self.question_templates = self._get_question_templates()
    
    def _get_question_templates(self) -> Dict[str, List[str]]:
        """Question templates for different analysis types."""
        return {
            "correlation": [
                "Is there a relationship between {col1} and {col2}?",
                "Does {col1} predict {col2}?",
                "How strongly are {col1} and {col2} correlated?"
            ],
            "comparison": [
                "Does {numeric_col} vary across different {cat_col} groups?",
                "Which {cat_col} has the highest {numeric_col}?",
                "Are there significant differences in {numeric_col} between {cat_col} categories?"
            ],
            "trend": [
                "Is there a trend in {numeric_col} over {temporal_col}?",
                "How has {numeric_col} changed over time?",
                "Is {numeric_col} increasing or decreasing?"
            ],
            "subspace": [
                "Is the relationship between {col1} and {col2} different for specific {cat_col} values?",
                "Are there segments where {col1} and {col2} correlate more strongly?",
                "Does {cat_col} moderate the relationship between {col1} and {col2}?"
            ],
            "anomaly": [
                "Are there outliers in {numeric_col}?",
                "Which {cat_col} categories have unusual {numeric_col} values?",
                "Are there unexpected patterns in {numeric_col}?"
            ]
        }
    
    async def generate_questions_llm(self, 
                                     df: pl.DataFrame,
                                     column_metadata: Dict[str, Any],
                                     llm_router=None,
                                     max_questions: int = 15) -> List[AnalyticalQuestion]:
        """
        Generate questions using LLM based on dataset semantics.
        Falls back to template-based generation if LLM unavailable.
        """
        if llm_router is None:
            return self.generate_questions_template(df, max_questions)
        
        try:
            # Build context for LLM
            numeric_cols = df.select(pl.col(pl.NUMERIC_DTYPES)).columns
            categorical_cols = df.select(pl.col([pl.Utf8, pl.Categorical])).columns
            temporal_cols = df.select(pl.col([pl.Date, pl.Datetime])).columns
            
            prompt = f"""You are a senior data analyst. Given this dataset schema, generate {max_questions} analytical questions that would reveal valuable business insights.

Dataset: {df.shape[0]} rows, {df.shape[1]} columns

Columns:
- Numeric: {', '.join(numeric_cols[:10])}
- Categorical: {', '.join(categorical_cols[:10])}
- Temporal: {', '.join(temporal_cols[:5])}

Generate questions in JSON format:
[
  {{"question": "...", "type": "correlation|comparison|trend|subspace|anomaly", "columns": ["col1", "col2"], "priority": 1-10}}
]

Focus on:
1. Correlations between numeric columns
2. Differences across categorical groups
3. Time trends if temporal data exists
4. Subspace patterns (e.g., "Does X correlate with Y only for segment Z?")
5. Anomalies and outliers

Return ONLY valid JSON array."""

            response = await llm_router.call(
                task="kpi_suggestion",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                expect_json=True
            )
            
            # Parse response
            questions = []
            try:
                parsed = json.loads(response) if isinstance(response, str) else response
                if isinstance(parsed, list):
                    for q in parsed[:max_questions]:
                        questions.append(AnalyticalQuestion(
                            question=q.get("question", ""),
                            question_type=q.get("type", "correlation"),
                            target_columns=q.get("columns", []),
                            priority=float(q.get("priority", 5)) / 10
                        ))
            except json.JSONDecodeError:
                logger.warning("Failed to parse LLM questions, falling back to templates")
                return self.generate_questions_template(df, max_questions)
            
            return questions
            
        except Exception as e:
            logger.warning(f"LLM question generation failed: {e}, using templates")
            return self.generate_questions_template(df, max_questions)
    
    def generate_questions_template(self, df: pl.DataFrame, max_questions: int = 15) -> List[AnalyticalQuestion]:
        """Template-based question generation (no LLM required)."""
        questions = []
        
        numeric_cols = df.select(pl.col(pl.NUMERIC_DTYPES)).columns
        categorical_cols = df.select(pl.col([pl.Utf8, pl.Categorical])).columns
        temporal_cols = df.select(pl.col([pl.Date, pl.Datetime])).columns
        
        # Correlation questions
        for col1, col2 in list(combinations(numeric_cols[:6], 2))[:5]:
            questions.append(AnalyticalQuestion(
                question=f"Is there a relationship between {col1} and {col2}?",
                question_type="correlation",
                target_columns=[col1, col2],
                priority=0.8
            ))
        
        # Comparison questions
        for cat_col in categorical_cols[:3]:
            for num_col in numeric_cols[:2]:
                questions.append(AnalyticalQuestion(
                    question=f"Does {num_col} vary across {cat_col} groups?",
                    question_type="comparison",
                    target_columns=[num_col],
                    filter_column=cat_col,
                    priority=0.7
                ))
        
        # Subspace questions
        for col1, col2 in list(combinations(numeric_cols[:4], 2))[:3]:
            for cat_col in categorical_cols[:2]:
                questions.append(AnalyticalQuestion(
                    question=f"Is {col1} vs {col2} correlation different across {cat_col}?",
                    question_type="subspace",
                    target_columns=[col1, col2],
                    filter_column=cat_col,
                    priority=0.9
                ))
        
        # Trend questions
        for temp_col in temporal_cols[:1]:
            for num_col in numeric_cols[:2]:
                questions.append(AnalyticalQuestion(
                    question=f"Is there a trend in {num_col} over {temp_col}?",
                    question_type="trend",
                    target_columns=[num_col, temp_col],
                    priority=0.85
                ))
        
        # Sort by priority and limit
        questions.sort(key=lambda q: q.priority, reverse=True)
        return questions[:max_questions]


# ============================================================
# STATISTICAL TESTS FOR QUIS
# ============================================================

class QUISStatistics:
    """Statistical methods specific to QUIS analysis."""
    
    @staticmethod
    def fisher_z_test(r1: float, n1: int, r2: float, n2: int) -> Tuple[float, float]:
        """
        Fisher's z-test to compare two correlation coefficients.
        Returns (z_statistic, p_value).
        
        Used to determine if a correlation is significantly different in a subspace.
        """
        # Fisher's r-to-z transformation
        def r_to_z(r):
            # Clamp to avoid infinity
            r = np.clip(r, -0.9999, 0.9999)
            return 0.5 * np.log((1 + r) / (1 - r))
        
        z1 = r_to_z(r1)
        z2 = r_to_z(r2)
        
        # Standard error of difference
        se = np.sqrt(1/(n1 - 3) + 1/(n2 - 3))
        
        # Z statistic
        z_stat = (z1 - z2) / se if se > 0 else 0
        
        # Two-tailed p-value
        p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))
        
        return round(z_stat, 4), round(p_value, 6)
    
    @staticmethod
    def cohens_q(r1: float, r2: float) -> Tuple[float, str]:
        """
        Cohen's q for effect size of correlation difference.
        
        Interpretation:
        - |q| < 0.1: negligible
        - 0.1 <= |q| < 0.3: small
        - 0.3 <= |q| < 0.5: medium
        - |q| >= 0.5: large
        """
        def r_to_z(r):
            r = np.clip(r, -0.9999, 0.9999)
            return 0.5 * np.log((1 + r) / (1 - r))
        
        q = abs(r_to_z(r1) - r_to_z(r2))
        
        if q < 0.1:
            interpretation = "negligible"
        elif q < 0.3:
            interpretation = "small"
        elif q < 0.5:
            interpretation = "medium"
        else:
            interpretation = "large"
        
        return round(q, 4), interpretation
    
    @staticmethod
    def benjamini_hochberg(p_values: List[float], alpha: float = 0.05) -> List[bool]:
        """
        Benjamini-Hochberg procedure for FDR control.
        
        Returns list of booleans indicating which hypotheses are significant
        after controlling false discovery rate at alpha level.
        """
        n = len(p_values)
        if n == 0:
            return []
        
        # Create indexed p-values and sort
        indexed = list(enumerate(p_values))
        indexed.sort(key=lambda x: x[1])
        
        # Calculate BH critical values
        significant = [False] * n
        
        for rank, (orig_idx, p) in enumerate(indexed, 1):
            # BH critical value: (rank / n) * alpha
            critical = (rank / n) * alpha
            if p <= critical:
                # All hypotheses with smaller p-values are also significant
                for j in range(rank):
                    significant[indexed[j][0]] = True
        
        return significant


# ============================================================
# BEAM SEARCH SUBSPACE EXPLORER
# ============================================================

class BeamSearchExplorer:
    """
    Beam search for intelligent subspace exploration.
    Prunes unpromising branches early.
    """
    
    def __init__(self, beam_width: int = 10, max_depth: int = 2):
        self.beam_width = beam_width
        self.max_depth = max_depth
        self.stats = QUISStatistics()
    
    def explore_correlation_subspaces(self, 
                                       df: pl.DataFrame,
                                       col1: str, 
                                       col2: str,
                                       categorical_cols: List[str],
                                       base_correlation: float,
                                       base_n: int) -> List[QUISInsight]:
        """
        Explore subspaces where correlation might be stronger using beam search.
        """
        insights = []
        
        # Initialize beam with empty subspace
        beam: List[SubspaceCandidate] = [
            SubspaceCandidate(filters={}, score=0.0, n_samples=len(df), depth=0)
        ]
        
        visited = set()
        
        for depth in range(1, self.max_depth + 1):
            next_beam = []
            
            for candidate in beam:
                # Skip if already visited
                filter_key = tuple(sorted(candidate.filters.items()))
                if filter_key in visited:
                    continue
                visited.add(filter_key)
                
                # Get current filtered dataframe
                filtered_df = df
                for col, val in candidate.filters.items():
                    filtered_df = filtered_df.filter(pl.col(col) == val)
                
                if len(filtered_df) < 20:
                    continue
                
                # Expand candidate with each categorical column
                for cat_col in categorical_cols:
                    if cat_col in candidate.filters:
                        continue
                    
                    unique_vals = filtered_df[cat_col].drop_nulls().unique().to_list()
                    if len(unique_vals) > 10:
                        continue
                    
                    for val in unique_vals[:5]:
                        subspace_df = filtered_df.filter(pl.col(cat_col) == val)
                        n_subspace = len(subspace_df)
                        
                        if n_subspace < 15:
                            continue
                        
                        # Calculate correlation in subspace
                        try:
                            x = subspace_df[col1].to_numpy()
                            y = subspace_df[col2].to_numpy()
                            mask = ~(np.isnan(x) | np.isnan(y))
                            x_clean, y_clean = x[mask], y[mask]
                            
                            if len(x_clean) < 10:
                                continue
                            
                            subspace_corr, _ = stats.pearsonr(x_clean, y_clean)
                            
                            # Score = correlation improvement
                            improvement = abs(subspace_corr) - abs(base_correlation)
                            
                            if improvement > 0.1:  # Promising improvement
                                new_filters = {**candidate.filters, cat_col: val}
                                next_beam.append(SubspaceCandidate(
                                    filters=new_filters,
                                    score=improvement,
                                    n_samples=n_subspace,
                                    depth=depth
                                ))
                                
                                # Test statistical significance
                                z_stat, p_value = self.stats.fisher_z_test(
                                    subspace_corr, n_subspace,
                                    base_correlation, base_n
                                )
                                
                                effect_size, effect_interp = self.stats.cohens_q(
                                    subspace_corr, base_correlation
                                )
                                
                                # Check for Simpson's Paradox (sign reversal)
                                is_simpson = (np.sign(subspace_corr) != np.sign(base_correlation) 
                                              and abs(subspace_corr) > 0.3)
                                
                                insights.append(QUISInsight(
                                    insight_type="subspace_correlation",
                                    description=self._describe_subspace_insight(
                                        col1, col2, new_filters, 
                                        base_correlation, subspace_corr, is_simpson
                                    ),
                                    columns=[col1, col2],
                                    subspace=new_filters,
                                    statistic=round(subspace_corr, 4),
                                    p_value=p_value,
                                    effect_size=effect_size,
                                    effect_interpretation=effect_interp,
                                    sample_size=n_subspace,
                                    is_simpson_paradox=is_simpson,
                                    novelty_score=improvement
                                ))
                                
                        except Exception as e:
                            logger.debug(f"Subspace analysis failed: {e}")
                            continue
            
            # Keep top beam_width candidates
            next_beam.sort(key=lambda x: x.score, reverse=True)
            beam = next_beam[:self.beam_width]
            
            if not beam:
                break
        
        return insights
    
    def _describe_subspace_insight(self, col1: str, col2: str, 
                                    filters: Dict[str, Any],
                                    base_corr: float, subspace_corr: float,
                                    is_simpson: bool) -> str:
        """Generate human-readable description of subspace insight."""
        filter_desc = " AND ".join([f"{k}={v}" for k, v in filters.items()])
        
        if is_simpson:
            return (f"⚠️ SIMPSON'S PARADOX: Correlation between {col1} and {col2} "
                   f"reverses from {base_corr:.2f} to {subspace_corr:.2f} when {filter_desc}")
        else:
            direction = "stronger" if abs(subspace_corr) > abs(base_corr) else "weaker"
            return (f"Correlation between {col1} and {col2} is {direction} "
                   f"({base_corr:.2f} → {subspace_corr:.2f}) when {filter_desc}")


# ============================================================
# ISGEN: INSIGHT GENERATION ENGINE
# ============================================================

class InsightGenerator:
    """
    ISGEN: Generates statistically validated insights in response to questions.
    """
    
    def __init__(self):
        self.beam_explorer = BeamSearchExplorer(beam_width=10, max_depth=2)
        self.stats = QUISStatistics()
    
    def generate_insights(self, 
                          df: pl.DataFrame,
                          questions: List[AnalyticalQuestion]) -> List[QUISInsight]:
        """Generate insights for all questions."""
        all_insights = []
        
        for question in questions:
            try:
                if question.question_type == "correlation":
                    insights = self._analyze_correlation(df, question)
                elif question.question_type == "comparison":
                    insights = self._analyze_comparison(df, question)
                elif question.question_type == "subspace":
                    insights = self._analyze_subspace(df, question)
                elif question.question_type == "trend":
                    insights = self._analyze_trend(df, question)
                else:
                    insights = []
                
                all_insights.extend(insights)
                
            except Exception as e:
                logger.warning(f"Insight generation failed for question: {e}")
                continue
        
        return all_insights
    
    def _analyze_correlation(self, df: pl.DataFrame, 
                             question: AnalyticalQuestion) -> List[QUISInsight]:
        """Analyze correlation between two columns."""
        insights = []
        
        if len(question.target_columns) < 2:
            return insights
        
        col1, col2 = question.target_columns[:2]
        
        if col1 not in df.columns or col2 not in df.columns:
            return insights
        
        result = correlation_analyzer.analyze_correlation(
            df[col1].to_numpy(), df[col2].to_numpy(),
            col1, col2, method="pearson"
        )
        
        if abs(result.correlation) >= 0.2:
            insights.append(QUISInsight(
                insight_type="correlation",
                description=f"{result.strength.capitalize()} correlation between {col1} and {col2} (r={result.correlation:.3f})",
                columns=[col1, col2],
                statistic=result.correlation,
                p_value=result.p_value,
                effect_size=result.correlation ** 2,  # R-squared as effect
                effect_interpretation=result.strength,
                confidence_interval=result.confidence_interval,
                sample_size=result.sample_size,
                novelty_score=abs(result.correlation)
            ))
        
        return insights
    
    def _analyze_comparison(self, df: pl.DataFrame,
                            question: AnalyticalQuestion) -> List[QUISInsight]:
        """Analyze differences across groups."""
        insights = []
        
        if not question.target_columns or not question.filter_column:
            return insights
        
        num_col = question.target_columns[0]
        cat_col = question.filter_column
        
        if num_col not in df.columns or cat_col not in df.columns:
            return insights
        
        # Get groups
        unique_groups = df[cat_col].drop_nulls().unique().to_list()
        
        if len(unique_groups) < 2 or len(unique_groups) > 10:
            return insights
        
        group_data = []
        for group_val in unique_groups:
            data = df.filter(pl.col(cat_col) == group_val)[num_col].drop_nulls().to_numpy()
            if len(data) >= 5:
                group_data.append((group_val, data))
        
        if len(group_data) < 2:
            return insights
        
        # Perform appropriate test
        if len(group_data) == 2:
            result = hypothesis_tester.welch_t_test(group_data[0][1], group_data[1][1])
        else:
            arrays = [g[1] for g in group_data]
            result = hypothesis_tester.one_way_anova(*arrays)
        
        if result.p_value < 0.1:  # Include marginally significant
            insights.append(QUISInsight(
                insight_type="group_comparison",
                description=f"{num_col} differs across {cat_col} groups (p={result.p_value:.4f}, effect={result.effect_size_interpretation or 'unknown'})",
                columns=[num_col, cat_col],
                statistic=result.statistic,
                p_value=result.p_value,
                effect_size=result.effect_size or 0,
                effect_interpretation=result.effect_size_interpretation or "",
                confidence_interval=result.confidence_interval,
                sample_size=sum(len(g[1]) for g in group_data),
                novelty_score=1 - result.p_value  # Lower p = higher novelty
            ))
        
        return insights
    
    def _analyze_subspace(self, df: pl.DataFrame,
                          question: AnalyticalQuestion) -> List[QUISInsight]:
        """Analyze correlation differences in subspaces using beam search."""
        insights = []
        
        if len(question.target_columns) < 2:
            return insights
        
        col1, col2 = question.target_columns[:2]
        
        if col1 not in df.columns or col2 not in df.columns:
            return insights
        
        # Calculate base correlation
        x = df[col1].to_numpy()
        y = df[col2].to_numpy()
        mask = ~(np.isnan(x) | np.isnan(y))
        x_clean, y_clean = x[mask], y[mask]
        
        if len(x_clean) < 20:
            return insights
        
        base_corr, _ = stats.pearsonr(x_clean, y_clean)
        base_n = len(x_clean)
        
        # Get categorical columns for subspace search
        categorical_cols = df.select(pl.col([pl.Utf8, pl.Categorical])).columns
        
        if question.filter_column:
            categorical_cols = [question.filter_column] + [
                c for c in categorical_cols if c != question.filter_column
            ]
        
        # Beam search exploration
        subspace_insights = self.beam_explorer.explore_correlation_subspaces(
            df, col1, col2, categorical_cols[:5], base_corr, base_n
        )
        
        insights.extend(subspace_insights)
        
        return insights
    
    def _analyze_trend(self, df: pl.DataFrame,
                       question: AnalyticalQuestion) -> List[QUISInsight]:
        """Analyze time trends."""
        insights = []
        
        if len(question.target_columns) < 2:
            return insights
        
        num_col = question.target_columns[0]
        time_col = question.target_columns[1] if len(question.target_columns) > 1 else None
        
        if num_col not in df.columns:
            return insights
        
        data = df[num_col].drop_nulls().to_numpy()
        
        if len(data) < 20:
            return insights
        
        # Simple trend test using Spearman correlation with index
        indices = np.arange(len(data))
        trend_corr, p_value = stats.spearmanr(indices, data)
        
        if abs(trend_corr) > 0.3 and p_value < 0.05:
            direction = "increasing" if trend_corr > 0 else "decreasing"
            insights.append(QUISInsight(
                insight_type="trend",
                description=f"{num_col} shows {direction} trend (τ={trend_corr:.3f}, p={p_value:.4f})",
                columns=[num_col] + ([time_col] if time_col else []),
                statistic=trend_corr,
                p_value=p_value,
                effect_size=abs(trend_corr),
                effect_interpretation="strong" if abs(trend_corr) > 0.6 else "moderate",
                sample_size=len(data),
                novelty_score=abs(trend_corr)
            ))
        
        return insights


# ============================================================
# ENHANCED QUIS ORCHESTRATOR
# ============================================================

class EnhancedQUIS:
    """
    Main QUIS orchestrator combining QUGEN and ISGEN with statistical rigor.
    """
    
    def __init__(self, beam_width: int = 10, max_questions: int = 15, fdr_alpha: float = 0.05):
        self.question_generator = QuestionGenerator()
        self.insight_generator = InsightGenerator()
        self.stats = QUISStatistics()
        self.beam_width = beam_width
        self.max_questions = max_questions
        self.fdr_alpha = fdr_alpha
    
    async def run_analysis(self,
                           df: pl.DataFrame,
                           column_metadata: Optional[Dict[str, Any]] = None,
                           llm_router=None,
                           use_llm_questions: bool = True) -> Dict[str, Any]:
        """
        Run complete enhanced QUIS analysis.
        
        Args:
            df: Polars DataFrame to analyze
            column_metadata: Optional metadata about columns
            llm_router: LLM router for question generation (optional)
            use_llm_questions: Whether to use LLM for question generation
        
        Returns:
            Complete QUIS analysis results with FDR-corrected insights
        """
        logger.info(f"Starting Enhanced QUIS analysis on {df.shape[0]} rows, {df.shape[1]} columns")
        
        # Step 1: Generate questions (QUGEN)
        logger.info("Step 1: Generating analytical questions (QUGEN)")
        if use_llm_questions and llm_router:
            questions = await self.question_generator.generate_questions_llm(
                df, column_metadata or {}, llm_router, self.max_questions
            )
        else:
            questions = self.question_generator.generate_questions_template(df, self.max_questions)
        
        logger.info(f"Generated {len(questions)} analytical questions")
        
        # Step 2: Generate insights (ISGEN)
        logger.info("Step 2: Generating insights (ISGEN)")
        raw_insights = self.insight_generator.generate_insights(df, questions)
        logger.info(f"Generated {len(raw_insights)} raw insights")
        
        # Step 3: Apply FDR correction
        logger.info("Step 3: Applying Benjamini-Hochberg FDR correction")
        p_values = [ins.p_value for ins in raw_insights]
        significant_mask = self.stats.benjamini_hochberg(p_values, self.fdr_alpha)
        
        significant_insights = [
            ins for ins, is_sig in zip(raw_insights, significant_mask) if is_sig
        ]
        logger.info(f"After FDR correction: {len(significant_insights)} significant insights")
        
        # Step 4: Calculate overall scores and rank
        logger.info("Step 4: Ranking insights")
        for insight in significant_insights:
            # Score = (1 - p_value) * effect_size * novelty
            insight.overall_score = (
                (1 - insight.p_value) * 
                (abs(insight.effect_size) if insight.effect_size else 0.5) *
                insight.novelty_score
            )
        
        # Sort by overall score
        significant_insights.sort(key=lambda x: x.overall_score, reverse=True)
        
        # Step 5: Identify Simpson's Paradox cases
        simpson_paradoxes = [ins for ins in significant_insights if ins.is_simpson_paradox]
        
        # Build results
        results = {
            "summary": {
                "total_questions": len(questions),
                "total_raw_insights": len(raw_insights),
                "significant_insights": len(significant_insights),
                "simpson_paradoxes_found": len(simpson_paradoxes),
                "fdr_alpha": self.fdr_alpha
            },
            "questions": [q.to_dict() for q in questions],
            "insights": [ins.to_dict() for ins in significant_insights[:50]],  # Top 50
            "simpson_paradoxes": [ins.to_dict() for ins in simpson_paradoxes],
            "top_insights": [ins.to_dict() for ins in significant_insights[:10]]  # Highlight top 10
        }
        
        logger.info(f"Enhanced QUIS analysis complete: {results['summary']}")
        return results
    
    def run_analysis_sync(self,
                          df: pl.DataFrame,
                          column_metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Synchronous version of QUIS analysis (no LLM questions).
        """
        import asyncio
        
        # If there's already a running event loop, use it
        try:
            loop = asyncio.get_running_loop()
            # We're in an async context, create a task
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(
                    asyncio.run,
                    self.run_analysis(df, column_metadata, None, False)
                )
                return future.result()
        except RuntimeError:
            # No running event loop, safe to use asyncio.run
            return asyncio.run(self.run_analysis(df, column_metadata, None, False))


# ============================================================
# SINGLETON INSTANCE
# ============================================================

enhanced_quis = EnhancedQUIS()
