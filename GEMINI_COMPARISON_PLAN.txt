================================================================================
       DATASAGE vs GEMINI APPROACH â€” COMPARISON & UNIFIED IMPLEMENTATION PLAN
================================================================================

Generated: February 10, 2026
Purpose: Compare current DataSage LangGraph implementation with Gemini's proposal

================================================================================
                            EXECUTIVE SUMMARY
================================================================================

VERDICT: Your existing implementation is MORE SOPHISTICATED than Gemini's.

Gemini proposes a basic 4-node graph. You already have:
- 6+ nodes with conditional branching
- Novelty filtering (Semantic + Bayesian Surprise)
- Belief Store integration
- QUIS research methodology
- Simpson's Paradox detection
- FDR correction for multiple testing

However, Gemini's critique about DataFrame in state is VALID and you've 
ALREADY SOLVED IT correctly.

================================================================================
                          SIDE-BY-SIDE COMPARISON
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ASPECT             â”‚ GEMINI'S PROPOSAL               â”‚ YOUR CURRENT IMPLEMENTATION     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Graph Topology     â”‚ planner â†’ analyst â†’             â”‚ planner â†’ analyst â†’ critic â†’    â”‚
â”‚                    â”‚ visualizer â†’ critic â†’ END       â”‚ novelty_filter â†’ synthesizer    â”‚
â”‚                    â”‚                                 â”‚ + conditional loops             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ State Management   â”‚ file_path only (no DataFrame)   â”‚ dataset_id + schema + samples   â”‚
â”‚                    â”‚ âœ… CORRECT                      â”‚ âœ… ALREADY CORRECT              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DataFrame Handling â”‚ Load in analyst node only       â”‚ Load in analyst node only       â”‚
â”‚                    â”‚                                 â”‚ (identical approach)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Critique Logic     â”‚ Simple "GOOD/BAD" string        â”‚ Structured CritiqueState with   â”‚
â”‚                    â”‚                                 â”‚ score, issues, suggestions      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Retry Mechanism    â”‚ critique_count < 2              â”‚ error_count < max_retries (3)   â”‚
â”‚                    â”‚                                 â”‚ + iteration_count < 50          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Novelty Filtering  â”‚ âŒ NOT IMPLEMENTED              â”‚ âœ… Semantic Surprisal +         â”‚
â”‚                    â”‚                                 â”‚ Bayesian Surprise hybrid        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Statistical Rigor  â”‚ Basic describe() + corr()      â”‚ Fisher's z-test, FDR            â”‚
â”‚                    â”‚                                 â”‚ correction, Effect size calc    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Question Gen       â”‚ Hardcoded list                  â”‚ LLM-driven QUGEN with           â”‚
â”‚                    â”‚                                 â”‚ template fallback               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Simpson's Paradox  â”‚ âŒ NOT IMPLEMENTED              â”‚ âœ… Explicit detection           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Output Format      â”‚ viz_configs (Plotly JSON)       â”‚ InsightState + final_response   â”‚
â”‚                    â”‚                                 â”‚ + approved_insights             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


================================================================================
                     WHAT GEMINI GOT RIGHT (ADOPT THESE)
================================================================================

1. âœ… LAZY LOADING PATTERN
   Gemini's approach:
   ```python
   lf = pl.scan_parquet(file_path)  # Lazy scan
   stats = lf.limit(100).collect().describe()
   ```
   
   Your approach already does this, but could add explicit LazyFrame for 
   initial schema detection to save memory on very large files.

2. âœ… VIZ DESIGNER AS SEPARATE NODE
   Gemini has `viz_designer_node` that generates Plotly JSON.
   
   You currently have chart hydration in a separate service (hydrate.py)
   but NOT as a LangGraph node. Consider adding this for consistency.

3. âœ… FRONTEND INTEGRATION PATTERN
   Gemini's React component pattern is cleaner:
   ```jsx
   {analysisData.plots.map((plotConfig, i) => (
     <Plot data={plotConfig.data} layout={plotConfig.layout} />
   ))}
   ```
   
   Your PlotlyChart component already does this, but the naming 
   convention could be standardized.


================================================================================
                      WHAT YOUR IMPLEMENTATION HAS BETTER
================================================================================

1. âœ… STRUCTURED STATE SCHEMA (state.py)
   - TypedDict with Annotated reducers for message history
   - Explicit QuestionState, InsightState, CritiqueState
   - Factory function create_initial_state() for proper initialization

2. âœ… NOVELTY FILTERING (novelty_filter_node)
   Gemini has NOTHING like this. Your implementation includes:
   - Semantic Surprisal (embedding distance)
   - Bayesian Surprise (KL divergence)
   - Hybrid score with configurable Î±=0.6
   - Belief Store integration for user-specific filtering

3. âœ… STATISTICAL SOPHISTICATION (enhanced_quis.py)
   - Beam search subspace exploration
   - Simpson's Paradox detection
   - FDR correction (Benjamini-Hochberg)
   - Effect size interpretation (Cohen's thresholds)

4. âœ… RESEARCH BACKING
   - QUIS paper (EMNLP 2024)
   - Your own Subjective Novelty Detection paper
   - Proper citations and methodology


================================================================================
                         GAPS TO FIX IN YOUR CODE
================================================================================

GAP 1: Chat Integration Missing
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Your LangGraph QUIS is NOT connected to the chat endpoint.
ai_service.py uses a completely different flow.

CURRENT CHAT FLOW:
  user query â†’ sanitize â†’ rewrite â†’ PromptFactory â†’ llm_router â†’ hydrate

QUIS FLOW (UNUSED IN CHAT):
  questions â†’ analyst â†’ critic â†’ novelty â†’ synthesizer

RECOMMENDATION: Add a "deep_analysis" mode that triggers the LangGraph.


GAP 2: Visualization Node Missing
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Your quis_graph.py generates InsightState but doesn't have a node that 
converts insights to Plotly configs.

RECOMMENDATION: Add viz_designer_node between critic and synthesizer.


GAP 3: Production Readiness
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PROJECT_OVERVIEW.md says: "âš ï¸ Partial â€” not fully production-tested"

RECOMMENDATION: Add integration tests and error boundary handling.


================================================================================
                        UNIFIED IMPLEMENTATION PLAN
================================================================================

PHASE 1: INTEGRATE LANGGRAPH WITH CHAT (Week 1)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1.1 Add "deep_analysis" mode to chat endpoint

File: api/chat.py
```python
@router.post("/datasets/{dataset_id}/analyze")
async def trigger_deep_analysis(
    dataset_id: str,
    request: AnalysisRequest,
    current_user: dict = Depends(get_current_user)
):
    """Trigger LangGraph QUIS analysis for complex queries."""
    from services.agents.quis_graph import run_quis_analysis
    
    result = await run_quis_analysis(
        dataset_id=dataset_id,
        user_id=current_user["id"],
        query=request.query,
        novelty_threshold=request.novelty_threshold or 0.35
    )
    
    return {
        "insights": result["approved_insights"],
        "plots": result.get("viz_configs", []),
        "boring_filtered": len(result.get("boring_insights", [])),
        "execution_time": result.get("execution_time")
    }
```

1.2 Add entry point function to quis_graph.py

```python
async def run_quis_analysis(
    dataset_id: str,
    user_id: str,
    query: str = None,
    novelty_threshold: float = 0.35
) -> Dict[str, Any]:
    """Public entry point for QUIS analysis."""
    
    # Get dataset metadata
    db = get_database()
    dataset = await db.datasets.find_one({"_id": ObjectId(dataset_id)})
    
    if not dataset:
        raise HTTPException(404, "Dataset not found")
    
    # Build lightweight schema summary
    df_sample = pl.scan_parquet(dataset["file_path"]).limit(5).collect()
    schema = {col: str(dtype) for col, dtype in df_sample.schema.items()}
    
    # Initialize state
    initial_state = create_initial_state(
        dataset_id=dataset_id,
        user_id=user_id,
        data_schema=json.dumps(schema),
        sample_rows=df_sample.to_pandas().to_string(),
        row_count=dataset.get("metadata", {}).get("row_count", 0),
        column_count=len(schema),
        novelty_threshold=novelty_threshold
    )
    
    # Add user query if provided
    if query:
        initial_state["messages"] = [{"role": "user", "content": query}]
    
    # Run graph
    result = await quis_workflow.ainvoke(initial_state)
    
    return result
```

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PHASE 2: ADD VISUALIZATION NODE (Week 2)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

2.1 Create viz_designer_node in quis_graph.py

```python
async def viz_designer_node(state: AgentState) -> Dict[str, Any]:
    """
    Convert approved insights into Plotly visualization configs.
    Uses chart_recommender logic to select best chart type per insight.
    """
    logger.info("[VIZ] Generating visualizations for approved insights")
    
    from services.charts.hydrate import hydrate_chart
    from services.datasets.chart_recommender import recommend_chart_type
    
    viz_configs = []
    
    for insight in state.get("approved_insights", []):
        insight_type = insight.get("insight_type", "correlation")
        columns = insight.get("columns", [])
        
        # Map insight type to chart type
        chart_type_map = {
            "correlation": "scatter",
            "comparison": "bar",
            "trend": "line",
            "distribution": "histogram",
            "anomaly": "box"
        }
        
        chart_type = chart_type_map.get(insight_type, "bar")
        
        # Load data for this insight
        db = get_database()
        dataset = await db.datasets.find_one({"_id": ObjectId(state["dataset_id"])})
        df = pl.read_parquet(dataset["file_path"])
        
        # Apply subspace filter if present
        if insight.get("subspace"):
            for col, val in insight["subspace"].items():
                if col in df.columns:
                    df = df.filter(pl.col(col) == val)
        
        # Generate Plotly config
        try:
            traces = hydrate_chart(df, columns, chart_type)
            
            viz_configs.append({
                "insight_id": insight.get("description", "")[:50],
                "data": traces,
                "layout": {
                    "title": insight.get("description", "Analysis Result"),
                    "paper_bgcolor": "rgba(0,0,0,0)",
                    "plot_bgcolor": "rgba(0,0,0,0)",
                    "font": {"color": "#e2e8f0"}
                }
            })
        except Exception as e:
            logger.warning(f"[VIZ] Failed to generate chart: {e}")
    
    return {"viz_configs": viz_configs}
```

2.2 Update graph edges to include viz node

```python
graph.add_node("viz_designer", viz_designer_node)
graph.add_edge("novelty_filter", "viz_designer")  # When novel
graph.add_edge("viz_designer", "synthesizer")
```

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PHASE 3: SMART ROUTING FROM CHAT (Week 3)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

3.1 Add complexity-based routing in ai_service.py

```python
async def process_chat_message(self, query: str, ...):
    """Route simple queries to direct LLM, complex to LangGraph QUIS."""
    
    complexity = QueryComplexityAnalyzer.classify(query)
    
    # Deep analysis triggers
    deep_triggers = [
        "analyze", "deep dive", "comprehensive", "all insights",
        "statistical", "correlations", "patterns", "anomalies",
        "compare all", "full analysis"
    ]
    
    use_langgraph = (
        complexity == "complex" or
        any(trigger in query.lower() for trigger in deep_triggers)
    )
    
    if use_langgraph:
        logger.info(f"Routing to LangGraph QUIS for complex query")
        from services.agents.quis_graph import run_quis_analysis
        
        result = await run_quis_analysis(
            dataset_id=dataset_id,
            user_id=user_id,
            query=query
        )
        
        # Convert QUIS output to chat response format
        return {
            "response": result.get("final_response", ""),
            "chart_config": result.get("viz_configs", []),
            "insights": result.get("approved_insights", []),
            "analysis_type": "deep_quis"
        }
    
    # Otherwise, use existing direct LLM flow
    return await self._process_simple_query(query, dataset_id, user_id, ...)
```

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PHASE 4: FRONTEND INTEGRATION (Week 4)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

4.1 Update Chat.jsx to handle multi-chart responses

```jsx
// In ChatMessage component, handle multiple charts
{!isUser && msg.chart_config && (
  <div className="mt-3 space-y-4">
    {/* Handle both single chart and array of charts */}
    {(Array.isArray(msg.chart_config) ? msg.chart_config : [msg.chart_config])
      .map((chartConfig, i) => (
        <div key={i} className="bg-slate-900/70 rounded-xl p-3 border border-slate-700/50">
          {chartConfig.insight_id && (
            <p className="text-xs text-slate-400 mb-2">{chartConfig.insight_id}</p>
          )}
          <PlotlyChart
            data={chartConfig.data}
            layout={{
              ...chartConfig.layout,
              height: 300,
              margin: { t: 40, b: 40, l: 50, r: 20 }
            }}
          />
        </div>
      ))}
  </div>
)}
```

4.2 Add "Deep Analysis" button in Chat UI

```jsx
<button
  onClick={() => handleSendMessage(null, `Analyze all patterns in ${selectedDataset.name}`)}
  className="px-3 py-1.5 bg-purple-600 hover:bg-purple-500 text-white text-sm rounded-lg"
>
  ğŸ”¬ Deep Analysis
</button>
```

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PHASE 5: TESTING & OBSERVABILITY (Week 5)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

5.1 Add pytest tests for LangGraph flow

```python
# tests/test_quis_graph.py

import pytest
from services.agents.quis_graph import run_quis_analysis
from services.agents.state import create_initial_state

@pytest.mark.asyncio
async def test_quis_simple_dataset():
    """Test QUIS analysis on sample dataset."""
    result = await run_quis_analysis(
        dataset_id="test_dataset_id",
        user_id="test_user",
        novelty_threshold=0.35
    )
    
    assert "approved_insights" in result
    assert "viz_configs" in result
    assert result.get("iteration_count", 0) < 50  # Didn't hit safety limit

@pytest.mark.asyncio
async def test_novelty_filtering():
    """Test that boring insights are filtered."""
    # First run: insight should be novel
    result1 = await run_quis_analysis(...)
    
    # Second run with same user: insight should be filtered as boring
    result2 = await run_quis_analysis(...)
    
    assert len(result2.get("boring_insights", [])) > 0
```

5.2 Add LangSmith tracing (if using LangGraph)

```python
# In quis_graph.py
from langgraph.checkpoint.memory import MemorySaver

checkpointer = MemorySaver()
quis_workflow = graph.compile(checkpointer=checkpointer)

# Enable LangSmith tracing
import os
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "datasage-quis"
```


================================================================================
                           PRIORITY RECOMMENDATIONS
================================================================================

IMMEDIATE (This Week):
1. âœ… Confirm LangGraph is installed and working: pip install langgraph
2. âœ… Add the run_quis_analysis() entry point function
3. âœ… Add /analyze endpoint to chat.py

SHORT-TERM (Next 2 Weeks):
4. Add viz_designer_node to generate Plotly configs
5. Implement smart routing based on query complexity
6. Update frontend to handle multi-chart responses

MEDIUM-TERM (Next Month):
7. Add comprehensive pytest tests
8. Enable LangSmith for observability
9. Performance optimization (caching, lazy loading)

LOW PRIORITY (Future):
10. Add streaming for LangGraph responses
11. Implement human-in-the-loop patterns
12. Multi-dataset analysis support


================================================================================
                              CONCLUSION
================================================================================

Your existing QUIS implementation is SUPERIOR to Gemini's proposal in:
- Statistical rigor
- Novelty filtering
- Research backing
- State management (already solved the DataFrame issue)

What's MISSING is the INTEGRATION:
- LangGraph is not connected to chat
- No viz_designer_node
- No smart routing

The plan above bridges this gap in 5 phases over ~5 weeks.

RECOMMENDED NEXT STEP:
Run `pip install langgraph` and verify the existing quis_graph.py compiles
without errors. Then add the run_quis_analysis() entry point.

================================================================================
